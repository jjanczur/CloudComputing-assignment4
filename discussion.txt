discussion.txt

Run your programs with different job configurations:
Two worker nodes
#WordCount

parallelism=1; execution time1 8
parallelism=2; execution time 11
parallelism=4; execution time 22

#CellCluster (berlin)

parallelism=1; execution time18
parallelism=2; execution time11
parallelism=4; execution time22

Parallelism set to 2 performed the best. 
That is why the following tests are going to be conducted using parallelism set ot 2.

--iterations  10 --mnc 1;6;78 --k 500 #  execution time 14
--iterations 100 --mnc 1;6;78 --k 500 #  execution time 36
--iterations 500 --mnc 1;6;78 --k 500 #  execution time 99

--iterations 100 --mnc 1;6;78 --k  100 #  execution time [s]: 31
--iterations 100 --mnc 1;6;78 --k  500 #  execution time [s]: 34
--iterations 100 --mnc 1;6;78 --k 1000 #  execution time [s]: 38

We obtained different initial placement by shuffling the input
(head -n 1 ./berlin.csv && tail -n +2 berlin.csv  | shuf) > ./berlin2.csv

--input s3://tub-cc-assignment4-flink/berlin2.csv --iterations 100 --mnc 1;6;78 --k  500 # execution time 36s

Program performed similar with shuffled input.

5 worker nodes:

--input s3://tub-cc-assignment4-flink/tolstoy-war-and-peace.txt --output s3://tub-cc-assignment4-flink/wordcount.csv
parallelism=1 execution time 11s
parallelism=2 execution time 15s
parallelism=4 execution time 14s
parallelism=5 execution time 9s
parallelism=8 execution time 15s


--input s3://tub-cc-assignment4-flink/berlin.csv --iterations 100 --mnc 1;6;78 --k 500 --output s3://tub-cc-assignment4-flink/berlinClusters.csv

parallelism=1 execution time 38s
parallelism=2 execution time 28s
parallelism=4 execution time 45s
parallelism=5 execution time 30s
parallelism=8 execution time 37s


--input s3://tub-cc-assignment4-flink/germany.csv --iterations 100 --mnc 1;6;78 --k 500 --output s3://tub-cc-assignment4-flink/clusters.csv

parallelism=1 execution time 4m17s
parallelism=2 execution time 2m55s
parallelism=4 execution time 1m47s
parallelism=5 execution time 1m40s
parallelism=8 execution time 2m17s

Answer the following questions separately for both programs:
1. Which steps in your program require communication and synchronization between your workers?

Answers are based the flink web console
#WordCount.java
	Communication: between GroupCombine - GroupReduce, Sort-Partition - Data Sink.
	Synchronisation: is required while we are receiving the data. One Worker synchronization.

#CellCluster.java
	Communication: all steps
	Synchronisation: writing the output, while finding the first centroid in GroupReduce

2. What resources are your programs bound by? Memory? CPU? Network? Disk?

#WordCount.java
	Network - reading data from s3 bucket is the longest execution step in an optimal parallelism mode (2). It goes through the network. 

#CellCluster.java 
	CPU - in contrast to WordCount reading data from s3 bucket was the shortest execution part that is why we assume that in this case the program is bounded on CPU.

3. Could you improve the partitioning of your data to yield better run-time?

#WordCount.java
	No. Increasing parallelism resulted in worse runtime. Program is network bonded and parallelization in data reading by multiple workers won't help either due to communication overhead.

#CellCluster.java
	No. Increasing parallelism resulted in worse runtime. It also made the program network bonded instead of CPU.
